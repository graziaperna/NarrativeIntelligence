{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\user\\projectai\\.env\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (0.20.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: jsonlines in c:\\users\\user\\projectai\\.env\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user\\projectai\\.env\\lib\\site-packages (from jsonlines) (23.1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n",
    "%pip install jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = '../data/'\n",
    "dataset_path = os.path.join(os.getcwd(), data_path + 'annotations.jsonl')\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(dataset_path, 'r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendere colonne e metterle in variabili separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>La giornata spuntò serena e limpida per gli sp...</td>\n",
       "      <td>[[44, 49, PER], [87, 91, GPE], [132, 142, GPE]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I .\\nLa ditta portava il nome del padre Giovan...</td>\n",
       "      <td>[[7, 12, ORG], [33, 58, PER], [83, 107, PER], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I .\\nLa prima volta che Cesare Lascaris entrò ...</td>\n",
       "      <td>[[23, 38, PER], [48, 70, FAC], [59, 70, PER], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I .\\nDinanzi all ' osteria di Muzio Scevola , ...</td>\n",
       "      <td>[[18, 42, FAC], [48, 58, LOC], [139, 153, GPE]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anna così racconta : Per lungo tempo , l ' amo...</td>\n",
       "      <td>[[0, 4, PER], [64, 80, PER], [151, 179, PER], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>I .\\nEllade , giovinezza del mondo .\\nNel temp...</td>\n",
       "      <td>[[4, 10, GPE], [28, 33, LOC], [72, 78, PER], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>CAPITOLO PRIMO .\\nNel quale Phileas Fogg e Gam...</td>\n",
       "      <td>[[27, 39, PER], [42, 52, PER], [85, 88, PER], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Clotilde entrò un poco sbadatamente , cantando...</td>\n",
       "      <td>[[0, 8, PER], [53, 83, FAC], [75, 83, FAC], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>I .\\nSenza fiori nascosti nella sottoveste , m...</td>\n",
       "      <td>[[125, 138, PER], [200, 207, PER], [366, 372, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>I Dal primo all ' ultimo giorno della sua vita...</td>\n",
       "      <td>[[47, 67, PER], [105, 110, LOC], [122, 143, PE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  \\\n",
       "0     1  La giornata spuntò serena e limpida per gli sp...   \n",
       "1     2  I .\\nLa ditta portava il nome del padre Giovan...   \n",
       "2     3  I .\\nLa prima volta che Cesare Lascaris entrò ...   \n",
       "3     4  I .\\nDinanzi all ' osteria di Muzio Scevola , ...   \n",
       "4     5  Anna così racconta : Per lungo tempo , l ' amo...   \n",
       "..  ...                                                ...   \n",
       "95   96  I .\\nEllade , giovinezza del mondo .\\nNel temp...   \n",
       "96   97  CAPITOLO PRIMO .\\nNel quale Phileas Fogg e Gam...   \n",
       "97   98  Clotilde entrò un poco sbadatamente , cantando...   \n",
       "98   99  I .\\nSenza fiori nascosti nella sottoveste , m...   \n",
       "99  100  I Dal primo all ' ultimo giorno della sua vita...   \n",
       "\n",
       "                                                label  \n",
       "0   [[44, 49, PER], [87, 91, GPE], [132, 142, GPE]...  \n",
       "1   [[7, 12, ORG], [33, 58, PER], [83, 107, PER], ...  \n",
       "2   [[23, 38, PER], [48, 70, FAC], [59, 70, PER], ...  \n",
       "3   [[18, 42, FAC], [48, 58, LOC], [139, 153, GPE]...  \n",
       "4   [[0, 4, PER], [64, 80, PER], [151, 179, PER], ...  \n",
       "..                                                ...  \n",
       "95  [[4, 10, GPE], [28, 33, LOC], [72, 78, PER], [...  \n",
       "96  [[27, 39, PER], [42, 52, PER], [85, 88, PER], ...  \n",
       "97  [[0, 8, PER], [53, 83, FAC], [75, 83, FAC], [1...  \n",
       "98  [[125, 138, PER], [200, 207, PER], [366, 372, ...  \n",
       "99  [[47, 67, PER], [105, 110, LOC], [122, 143, PE...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "id_tmp = df['id'].astype(str)\n",
    "text_tmp = df['text'].astype(str)\n",
    "label_tmp = df['label'].astype(str)\n",
    "df.drop(['Comments'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendere da text parola che inizia e finisce con indice di label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'text', 'label', 'Comments'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import jsonlines\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "pattern = r'\\[(\\d+), (\\d+), \\'(\\w+)\\'\\]'\n",
    "lst = []\n",
    "\n",
    "output_path = os.path.join(os.getcwd(), data_path, 'datasetT5.jsonl')\n",
    "\n",
    "with jsonlines.open(output_path, 'w') as writer:\n",
    "\n",
    "    for index, sub in enumerate(label_tmp):\n",
    "        lst = re.findall(pattern, str(sub))\n",
    "        text = text_tmp[index]\n",
    "\n",
    "        # Dividi il testo in frasi\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence_targets = []\n",
    "            for item in lst:\n",
    "                start_index = int(item[0])\n",
    "                end_index = int(item[1])\n",
    "                entity_type = item[2]\n",
    "                entity_name = text[start_index:end_index + 1]\n",
    "\n",
    "                # Verifica se l'entità è all'interno della frase corrente\n",
    "                if start_index >= text.index(sentence) and end_index <= text.index(sentence) + len(sentence):\n",
    "                    sentence_targets.append(entity_name + \" [\" + entity_type + \"]\")\n",
    "\n",
    "            # Se ci sono entità nella frase corrente, crea una coppia source/target\n",
    "            if sentence_targets:\n",
    "                # Unisci i target in una singola stringa\n",
    "                target_str = \" \".join(sentence_targets)\n",
    "                writer.write({'source': sentence, 'target': target_str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testo intero\n",
    "import pandas as pd\n",
    "import re\n",
    "import jsonlines\n",
    "\n",
    "pattern = r'\\[(\\d+), (\\d+), \\'(\\w+)\\'\\]'\n",
    "lst = []\n",
    "\n",
    "source = []\n",
    "targets = []\n",
    "\n",
    "output_path = os.path.join(os.getcwd(), data_path + 'datasetT5.jsonl')\n",
    "\n",
    "with jsonlines.open(output_path, 'w') as writer:\n",
    "\n",
    "    for index, sub in enumerate(label_tmp):    \n",
    "        lst = re.findall(pattern, str(sub))\n",
    "        source = text_tmp[index]\n",
    "        for item in lst:\n",
    "            text_tmp[index] = text_tmp[index].replace('\\\"','\"')\n",
    "            start_index = int(item[0])\n",
    "            end_index = int(item[1])\n",
    "            if start_index > 0 and text_tmp[index][start_index - 1] == \" \":  \n",
    "                start_index -= 1  # Decrementa l'indice di inizio di 1\n",
    "                end_index -= 1  # Decrementa l'indice di fine di 1\n",
    "            if end_index < len(text_tmp[index]) - 1 and text_tmp[index][end_index + 1] == \" \":  # Se il carattere successivo è uno spazio\n",
    "                end_index += 1  # Incrementa l'indice di fine di 1\n",
    "            text_tmp_substring = text_tmp[index][start_index:end_index + 1]  # Incrementa di 1 l'indice di fine\n",
    "            targets.append(text_tmp_substring + \" [\" + item[2] + \"]\")\n",
    "            \n",
    "        writer.write({'source': source, 'targets': targets})\n",
    "        \n",
    "        targets = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
