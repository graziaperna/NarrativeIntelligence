{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graziaperna/NarrativeIntelligence/blob/mt5/IT5_seq2seq_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYcToc-iDcgG",
        "outputId": "4d355a65-5b51-4c5c-b39c-081721a4f81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'it5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gsarti/it5.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r it5/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9MAZpx0Dx8F",
        "outputId": "e2a3afd2-dd2d-4510-a9d0-be1030718891"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 1)) (4.37.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 2)) (2.17.1)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 3)) (0.3.13)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 5)) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 6)) (2.1.0+cu121)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 7)) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 8)) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r it5/requirements.txt (line 9)) (1.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r it5/requirements.txt (line 2)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r it5/requirements.txt (line 2)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r it5/requirements.txt (line 2)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r it5/requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r it5/requirements.txt (line 2)) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r it5/requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r it5/requirements.txt (line 2)) (3.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score->-r it5/requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score->-r it5/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score->-r it5/requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r it5/requirements.txt (line 6)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r it5/requirements.txt (line 6)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r it5/requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r it5/requirements.txt (line 6)) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r it5/requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r it5/requirements.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r it5/requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r it5/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r it5/requirements.txt (line 9)) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r it5/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r it5/requirements.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r it5/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r it5/requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r it5/requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r it5/requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]->-r it5/requirements.txt (line 1)) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r it5/requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r it5/requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r it5/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r it5/requirements.txt (line 3)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r it5/requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r it5/requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score->-r it5/requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r it5/requirements.txt (line 6)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ASWXocoGZAa",
        "outputId": "53b497b8-ac26-4b12-d2a4-71d0bd5de26e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.11 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.27.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!shuf datasetT5.jsonl > datasetT5_shuffle.jsonl"
      ],
      "metadata": {
        "id": "iHN-kRvXEdbs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "smax = 0\n",
        "savg = 0\n",
        "\n",
        "tmax = 0\n",
        "tavg = 0\n",
        "\n",
        "with open('datasetT5.jsonl', 'r') as f:\n",
        "  for line in f:\n",
        "    obj = json.loads(line)\n",
        "    sl = len(obj[\"source\"])\n",
        "    if (sl>smax):\n",
        "      smax = sl\n",
        "    tl = len(obj[\"target\"])\n",
        "    if (tl>tmax):\n",
        "      tmax = tl\n",
        "    savg += sl\n",
        "    tavg += tl\n",
        "\n",
        "print(smax)\n",
        "print(tmax)\n",
        "print(savg/100)\n",
        "print(tavg/100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAGhUTgqH2Bq",
        "outputId": "d310e6d0-d027-49b3-8064-58c5b97b008e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1549\n",
            "610\n",
            "10106.09\n",
            "3061.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l datasetT5_shuffle.jsonl\n",
        "!head -n 80 datasetT5_shuffle.jsonl > train_app.jsonl\n",
        "!tail -n 20 datasetT5_shuffle.jsonl > test.json\n",
        "!head -n 80 train_app.jsonl > train.json\n",
        "!tail -n 20 train_app.jsonl > val.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONl6Vz6DEmtJ",
        "outputId": "5ff2227e-96ed-4b27-df6a-6130db434d63"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7150 datasetT5_shuffle.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python it5/finetuning/run_seq2seq.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EpfbwvMKZCg",
        "outputId": "79157aab-cd59-4b64-ef0e-22689bc19b86"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-21 15:50:14.405060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-21 15:50:14.405137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-21 15:50:14.406871: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-21 15:50:15.995243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: run_seq2seq.py [-h] --model_name_or_path MODEL_NAME_OR_PATH [--config_name CONFIG_NAME]\n",
            "                      [--tokenizer_name TOKENIZER_NAME] [--cache_dir CACHE_DIR]\n",
            "                      [--use_fast_tokenizer [USE_FAST_TOKENIZER]] [--no_use_fast_tokenizer]\n",
            "                      [--model_revision MODEL_REVISION] [--use_auth_token USE_AUTH_TOKEN]\n",
            "                      [--resize_position_embeddings RESIZE_POSITION_EMBEDDINGS]\n",
            "                      [--from_flax [FROM_FLAX]] [--dataset_name DATASET_NAME]\n",
            "                      [--dataset_config_name DATASET_CONFIG_NAME] [--source_column SOURCE_COLUMN]\n",
            "                      [--target_column TARGET_COLUMN] [--train_file TRAIN_FILE]\n",
            "                      [--validation_file VALIDATION_FILE] [--test_file TEST_FILE]\n",
            "                      [--overwrite_cache [OVERWRITE_CACHE]]\n",
            "                      [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
            "                      [--max_source_length MAX_SOURCE_LENGTH]\n",
            "                      [--max_target_length MAX_TARGET_LENGTH]\n",
            "                      [--val_max_target_length VAL_MAX_TARGET_LENGTH]\n",
            "                      [--pad_to_max_length [PAD_TO_MAX_LENGTH]]\n",
            "                      [--max_train_samples MAX_TRAIN_SAMPLES]\n",
            "                      [--max_eval_samples MAX_EVAL_SAMPLES]\n",
            "                      [--max_predict_samples MAX_PREDICT_SAMPLES] [--num_beams NUM_BEAMS]\n",
            "                      [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]\n",
            "                      [--no_ignore_pad_token_for_loss] [--source_prefix SOURCE_PREFIX]\n",
            "                      --output_dir OUTPUT_DIR [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
            "                      [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]] [--do_predict [DO_PREDICT]]\n",
            "                      [--evaluation_strategy {no,steps,epoch}]\n",
            "                      [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
            "                      [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "                      [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "                      [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
            "                      [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
            "                      [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                      [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
            "                      [--eval_delay EVAL_DELAY] [--learning_rate LEARNING_RATE]\n",
            "                      [--weight_decay WEIGHT_DECAY] [--adam_beta1 ADAM_BETA1]\n",
            "                      [--adam_beta2 ADAM_BETA2] [--adam_epsilon ADAM_EPSILON]\n",
            "                      [--max_grad_norm MAX_GRAD_NORM] [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                      [--max_steps MAX_STEPS]\n",
            "                      [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau}]\n",
            "                      [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS] [--warmup_ratio WARMUP_RATIO]\n",
            "                      [--warmup_steps WARMUP_STEPS]\n",
            "                      [--log_level {detail,debug,info,warning,error,critical,passive}]\n",
            "                      [--log_level_replica {detail,debug,info,warning,error,critical,passive}]\n",
            "                      [--log_on_each_node [LOG_ON_EACH_NODE]] [--no_log_on_each_node]\n",
            "                      [--logging_dir LOGGING_DIR] [--logging_strategy {no,steps,epoch}]\n",
            "                      [--logging_first_step [LOGGING_FIRST_STEP]] [--logging_steps LOGGING_STEPS]\n",
            "                      [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
            "                      [--no_logging_nan_inf_filter] [--save_strategy {no,steps,epoch}]\n",
            "                      [--save_steps SAVE_STEPS] [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                      [--save_safetensors [SAVE_SAFETENSORS]] [--no_save_safetensors]\n",
            "                      [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
            "                      [--save_only_model [SAVE_ONLY_MODEL]] [--no_cuda [NO_CUDA]]\n",
            "                      [--use_cpu [USE_CPU]] [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]\n",
            "                      [--data_seed DATA_SEED] [--jit_mode_eval [JIT_MODE_EVAL]]\n",
            "                      [--use_ipex [USE_IPEX]] [--bf16 [BF16]] [--fp16 [FP16]]\n",
            "                      [--fp16_opt_level FP16_OPT_LEVEL]\n",
            "                      [--half_precision_backend {auto,apex,cpu_amp}]\n",
            "                      [--bf16_full_eval [BF16_FULL_EVAL]] [--fp16_full_eval [FP16_FULL_EVAL]]\n",
            "                      [--tf32 TF32] [--local_rank LOCAL_RANK]\n",
            "                      [--ddp_backend {nccl,gloo,mpi,ccl,hccl}] [--tpu_num_cores TPU_NUM_CORES]\n",
            "                      [--tpu_metrics_debug [TPU_METRICS_DEBUG]] [--debug DEBUG [DEBUG ...]]\n",
            "                      [--dataloader_drop_last [DATALOADER_DROP_LAST]] [--eval_steps EVAL_STEPS]\n",
            "                      [--dataloader_num_workers DATALOADER_NUM_WORKERS] [--past_index PAST_INDEX]\n",
            "                      [--run_name RUN_NAME] [--disable_tqdm DISABLE_TQDM]\n",
            "                      [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
            "                      [--no_remove_unused_columns] [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
            "                      [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
            "                      [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
            "                      [--greater_is_better GREATER_IS_BETTER]\n",
            "                      [--ignore_data_skip [IGNORE_DATA_SKIP]] [--fsdp FSDP]\n",
            "                      [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS] [--fsdp_config FSDP_CONFIG]\n",
            "                      [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
            "                      [--deepspeed DEEPSPEED] [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
            "                      [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop}]\n",
            "                      [--optim_args OPTIM_ARGS] [--adafactor [ADAFACTOR]]\n",
            "                      [--group_by_length [GROUP_BY_LENGTH]]\n",
            "                      [--length_column_name LENGTH_COLUMN_NAME]\n",
            "                      [--report_to REPORT_TO [REPORT_TO ...]]\n",
            "                      [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
            "                      [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
            "                      [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]\n",
            "                      [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
            "                      [--no_dataloader_pin_memory]\n",
            "                      [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]\n",
            "                      [--skip_memory_metrics [SKIP_MEMORY_METRICS]] [--no_skip_memory_metrics]\n",
            "                      [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
            "                      [--push_to_hub [PUSH_TO_HUB]]\n",
            "                      [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "                      [--hub_model_id HUB_MODEL_ID]\n",
            "                      [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
            "                      [--hub_token HUB_TOKEN] [--hub_private_repo [HUB_PRIVATE_REPO]]\n",
            "                      [--hub_always_push [HUB_ALWAYS_PUSH]]\n",
            "                      [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
            "                      [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]\n",
            "                      [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
            "                      [--fp16_backend {auto,apex,cpu_amp}]\n",
            "                      [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
            "                      [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
            "                      [--push_to_hub_token PUSH_TO_HUB_TOKEN] [--mp_parameters MP_PARAMETERS]\n",
            "                      [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
            "                      [--full_determinism [FULL_DETERMINISM]] [--torchdynamo TORCHDYNAMO]\n",
            "                      [--ray_scope RAY_SCOPE] [--ddp_timeout DDP_TIMEOUT]\n",
            "                      [--torch_compile [TORCH_COMPILE]]\n",
            "                      [--torch_compile_backend TORCH_COMPILE_BACKEND]\n",
            "                      [--torch_compile_mode TORCH_COMPILE_MODE]\n",
            "                      [--dispatch_batches DISPATCH_BATCHES] [--split_batches [SPLIT_BATCHES]]\n",
            "                      [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]\n",
            "                      [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]\n",
            "                      [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]\n",
            "                      [--sortish_sampler [SORTISH_SAMPLER]]\n",
            "                      [--predict_with_generate [PREDICT_WITH_GENERATE]]\n",
            "                      [--generation_max_length GENERATION_MAX_LENGTH]\n",
            "                      [--generation_num_beams GENERATION_NUM_BEAMS]\n",
            "                      [--generation_config GENERATION_CONFIG]\n",
            "run_seq2seq.py: error: the following arguments are required: --model_name_or_path, --output_dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python it5/finetuning/run_seq2seq.py --model_name_or_path gsarti/it5-small --tokenizer_name gsarti/it5-small --source_column source --target_column target --train_file train.json --test_file test.json --validation_file val.json --max_source_length 1024 --max_target_length 256 --per_gpu_train_batch_size 16 --per_device_train_batch_size 16 --output_dir model_ner_small --do_train --evaluation_strategy epoch --num_train_epochs 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iqhLlsLD8Bm",
        "outputId": "e725e9b8-103e-4ffa-9918-1b867ecb8708"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-21 15:55:29.588953: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-21 15:55:29.589712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-21 15:55:29.592150: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-21 15:55:31.585811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "02/21/2024 15:55:33 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\n",
            "Generating train split: 80 examples [00:00, 18609.30 examples/s]\n",
            "Generating valid split: 20 examples [00:00, 10868.89 examples/s]\n",
            "Generating test split: 20 examples [00:00, 11942.78 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Running tokenizer on train dataset:   0% 0/80 [00:00<?, ? examples/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Running tokenizer on train dataset: 100% 80/80 [00:00<00:00, 1800.65 examples/s]\n",
            "Running tokenizer on validation dataset: 100% 20/20 [00:00<00:00, 992.24 examples/s]\n",
            "/content/it5/finetuning/run_seq2seq.py:517: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"rouge\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:753: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 5.65kB [00:00, 9.02MB/s]       \n",
            "[WARNING|training_args.py:1796] 2024-02-21 15:55:35,546 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[WARNING|training_args.py:1796] 2024-02-21 15:55:35,546 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            " 33% 5/15 [01:21<02:44, 16.45s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:03<00:01,  1.92s/it]\u001b[A\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 4.909962177276611, 'eval_runtime': 5.4503, 'eval_samples_per_second': 3.67, 'eval_steps_per_second': 0.55, 'epoch': 1.0}\n",
            " 33% 5/15 [01:26<02:44, 16.45s/it]\n",
            "100% 3/3 [00:04<00:00,  1.29s/it]\u001b[A\n",
            " 67% 10/15 [02:30<01:16, 15.38s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.46s/it]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 4.271397113800049, 'eval_runtime': 4.4961, 'eval_samples_per_second': 4.448, 'eval_steps_per_second': 0.667, 'epoch': 2.0}\n",
            " 67% 10/15 [02:34<01:16, 15.38s/it]\n",
            "100% 3/3 [00:03<00:00,  1.02s/it]\u001b[A\n",
            "100% 15/15 [03:37<00:00, 12.92s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.46s/it]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 4.051950454711914, 'eval_runtime': 4.5136, 'eval_samples_per_second': 4.431, 'eval_steps_per_second': 0.665, 'epoch': 3.0}\n",
            "100% 15/15 [03:41<00:00, 12.92s/it]\n",
            "100% 3/3 [00:03<00:00,  1.04s/it]\u001b[A\n",
            "{'train_runtime': 221.7258, 'train_samples_per_second': 1.082, 'train_steps_per_second': 0.068, 'train_loss': 5.109566243489583, 'epoch': 3.0}\n",
            "100% 15/15 [03:41<00:00, 14.78s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     5.1096\n",
            "  train_runtime            = 0:03:41.72\n",
            "  train_samples            =         80\n",
            "  train_samples_per_second =      1.082\n",
            "  train_steps_per_second   =      0.068\n",
            "100% 3/3 [00:03<00:00,  1.11s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_loss               =      4.052\n",
            "  eval_runtime            = 0:00:04.52\n",
            "  eval_samples            =         20\n",
            "  eval_samples_per_second =      4.423\n",
            "  eval_steps_per_second   =      0.663\n",
            "[WARNING|training_args.py:1796] 2024-02-21 15:59:27,891 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[WARNING|training_args.py:1796] 2024-02-21 15:59:27,891 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        }
      ]
    }
  ]
}